#' @title  Build multigroups model
#' @description MulGroupsCros function is designed to integrate the multi-group data to predict the incidence risk.
#'     It mainly aims to construct various stacked generalization models to predict the probability of outcome
#'     incidence, as well as providing the statistical explanation.
#' @usage eSet = MulGroupsCros(eSet = eSet,Groups = c("Exposure","Biomarker"),
#'                     VarsY = c("Y1"),VarsC = "all.c",TuneMethod = "grid_search",TuneNum = 5,RsmpMethod = "cv",
#'                     Folds = 5,VarsImpThr = 0.85,SG_Lrns = c("rf","xgboost"))
#' @param eSet An R6 class object
#' @param Groups chr. Groups to be integrated. The groups of outcome and covariates or
#'     confounders are not included. Note that separates different learners by "," and without space(e.g. Groups = "exposure, biomarker").
#' @param VarsY chr. Outcome variable for modelling. Only one variable can be entered.
#' @param VarsC chr. Covariates needing further statistical test. "all.c" option refers to all covariate variables listed in the data file.
#'     Users can also select part of them by copying available vars. Note that separates different vars by "," and without space(e.g. VarsC = "C1,C2").
#' @param TuneMethod chr. Method for hyper-parameter autotuning.
#'     Options include "default", "random_search", "grid_search", "nloptr"(Non-linear optimization), and "gensa"(Generalized simulated annealing).
#'     The "default" option uses the simple training method for parameter optimization of mlr3 package.
#' @param TuneNum num. Upper limit of model tuning times. It should be more than 20 times to search the appropriate parameters,
#'     but it takes more time. In theory, more time, better training results.
#' @param RsmpMethod chr. Method for resampling. Options include "cv"(cross validation), "loo"(leave-one-out cross validation),
#'     "bootstrap"(bootstrapping), "holdout"(holdout).
#' @param Folds num. Folds for cross validation resampling method. The default value is 5.
#' @param Ratio num. Ratio for "Holdout" resampling method. The default value is 5.
#' @param Repeats num. Repeats for "Bootstrap" resampling method.
#' @param VarsImpThr num. Threshold for feature selection.
#'     It refers to the ratio of accumulated importance of all variables of the selected variables for building the final model.
#' @param SG_Lrns chr. Learners for stacked generalization. Options include "lasso", "enet"(Elastic net), "rf"(Random forest), and "xgboost"(Xgboost).
#'     One or more arbitrary options can be selected at the same time. Note that separates different learners by "," and without space(e.g. SG_Lrns ="lasso,enet,rf,xgboost").
#' @details The calculation time depends on the characteristics of your data, the number of learning methods,
#'     and the tuning method. For parameter "TuneMethod", the default option can provide faster calculations but less accurate
#'     results than other autotune methods. If you want to train a better model, choose other auto-tune method and increase the number of tuning times.
#'
#' @return An R6 class object containing eight elements. The elements of that object include:
#' (1) "Importance": A list containing dataframes that contain the importance of features after modeling a single group from different groups.
#' (2) "Feature": A list containing dataframes that contain the the coefficients or importance of selected features after modeling a single group from different learners.
#' (3) "Feature_select": A list containing dataframes that contain the selected features after modeling a single group from different learners.
#' (4) "ModelStat": A list containing dataframes that contain the r-square value of the single group model built by different learners.
#' (5) "Prediction_comp": A list containing dataframes that contain the prediction values of the SG model built by different combinations of learners.
#' (6) "SGModel_summary": A dataframe containing the r-square value of the SG model built by different combinations of learners.
#' (7) "NodeNum": The node number generated by different models.
#' (8) "SGplot": A visualized plot for SG model summary.
#' @export
#' @examples
#'    eSet = InitEX(PID = "EX", FileDirIn = "default", FileDirOut = "default")
#' eSet = LoadEX(eSet = eSet,UseExample = "default",FileDirExpo = "examdata.xlsx",FileDirVoca = "examvoca.xlsx")
#' eSet = TransImput(eSet = eSet,Group = T,Vars = "all.e",Method = "lod")
#' eSet = DelLowVar(eSet = eSet)
#' eSet = DelMiss(eSet = eSet)
#' eSet = TransType(eSet = eSet,Vars = c("Y1", "C1","E203","E204","E207","E209"),TypeTo = "factor")
#' eSet = TransScale(eSet = eSet,Group = T,Vars = "all.e",Method = "normal",
#'                   Direct = "positive",RangeLow = 0,RangeUpper = 1)
#' eSet = TransDistr(eSet = eSet,Vars = c("C2", "C3"), Method = "log2")
#' eSet = TransDummy(eSet = eSet,Vars = "default")
#' eSet = MulGroupsCros(eSet = eSet,Groups = c("Exposure","Biomarker"),
#'                     VarsY = c("Y1"),VarsC = "all.c",TuneMethod = "grid_search",TuneNum = 5,RsmpMethod = "cv",
#'                     Folds = 5,VarsImpThr = 0.85,SG_Lrns = c("rf","xgboost"))
#' @author Guohuan Zhang, Yuting Wang, Bin Wang (corresponding author)
MulGroupsCros <- function(eSet,
                         Groups,
                         VarsY,
                         VarsC = NULL,
                         TuneMethod = "random_search",
                         TuneNum = "5",
                         RsmpMethod = "cv",
                         Folds = "5",
                         Ratio = NULL,
                         Repeats = NULL,
                         VarsImpThr = 0.85,
                         SG_Lrns = c("lasso","enet","rf","xgboost")
){
  tictoc::tic()

  Path = stringr::str_c(eSet$FileDirOut)
  if(!file.exists(Path)) {dir.create(Path)}

  #define variable
  if (all(VarsC == "all.c")){
    eSet$Expo$Voca %>%
      dplyr::filter(str_detect(SerialNo, "C")) %>%
      .$SerialNo -> VarsC
  }

  # Define single omics process ---------------------------------------------------------
  single.omics = function(OmicGroup,
                          VarY,
                          VarsC,
                          SG_Lrns,
                          TuneMethod,
                          TuneNum,
                          task,
                          pred.type,
                          measure_key,
                          measure_key_tune,
                          measure_id,
                          set_task,
                          resampling){

    # creat folder
    if(!file.exists(str_c(Path,"/1_",OmicGroup))){
      dir.create(str_c(Path,"/1_",OmicGroup))
    }
    if(!file.exists(str_c(Path,"/1_",OmicGroup,"/Feature_Explain"))){
      dir.create(str_c(Path,"/1_",OmicGroup,"/Feature_Explain"))
    }
    if(!file.exists(str_c(Path,"/1_",OmicGroup,"/Features_Selection"))){
      dir.create(str_c(Path,"/1_",OmicGroup,"/Features_Selection"))
    }
    if(!file.exists(str_c(Path,"/1_",OmicGroup,"/Model_Summary"))){
      dir.create(str_c(Path,"/1_",OmicGroup,"/Model_Summary"))
    }
    # if(!file.exists(str_c(Path,"/1_",OmicGroup,"/Viz_Intraomic.Networks"))){
    #   dir.create(str_c(Path,"/1_",OmicGroup,"/Viz_Intraomic.Networks"))
    # }
    #
    lubridate::now() %>%
      stringr::str_replace_all(":",".") %>%
      stringr::str_replace_all("-",".") -> NowTime

    message(stringr::str_c("Folder for ",OmicGroup," has been created!",NowTime))
    eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Folder for ",OmicGroup," has been created!",NowTime))
    message(stringr::str_c("Step1: Building machine learning models for ",OmicGroup," ...",NowTime))
    eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Step1: Building machine learning models for ",OmicGroup," ...",NowTime))
    # define data -------------------------------------------------------------
    eSet$MulOmics$OmicGroup.all <- c(eSet$MulOmics$OmicGroup.all,OmicGroup) # record Omics groups loaded

    VarsX <- eSet$Expo$Voca %>% dplyr::filter(GroupName==OmicGroup) %>% dplyr::select(SerialNo) %>% as.matrix() %>% as.vector()

    eSet$Expo$Data %>%
      dplyr::filter(Group == "train") %>%
      dplyr::select(all_of(VarY),
                    all_of(VarsX),
                    all_of(VarsC)) -> df.all.train

    eSet$Expo$Data %>%
      dplyr::filter(Group == "test") %>%
      dplyr::select(all_of(VarY),
                    all_of(VarsX),
                    all_of(VarsC)) -> df.all.test

    # feature selection & Build model ---------------------------------------------------------
    df.all.train %>%
      set_task(target = VarY) -> task0.train

    ls_features = list()
    bm_task = c()
    bm_learners = c()
    ls_models = list()

    if("lasso" %in% SG_Lrns){
      # feature selection_lasso
      learner_lasso = lrn(str_c(task,".cv_glmnet"),
                          predict_type = pred.type,
                          predict_sets = c("train", "test"),
                          id = "lasso")
      learner_lasso$param_set$values = list(alpha = 1)
      learner_lasso$train(task0.train)
      learner_lasso$selected_features(lambda = learner_lasso$model$lambda.1se) -> features_lasso
      eSet$Expo$Voca %>%
        dplyr::filter(SerialNo %in% features_lasso) %>%
        writexl::write_xlsx(str_c(Path,"/1_",
                                  OmicGroup,
                                  "/Features_Selection/Selected.features_lasso.xlsx"))
      # Save coefficients
      learner_lasso$model %>% stats::coef(s='lambda.1se') %>% as.matrix -> Coef_lasso
      Coef_lasso %>%
        as_tibble() %>%
        purrr::set_names("Coef") %>%
        dplyr::mutate(SerialNo = rownames(Coef_lasso)) -> eSet$MulOmics[[OmicGroup]]$Features$Coef$lasso

      eSet$MulOmics[[OmicGroup]]$Features$Coef$lasso %>%
        writexl::write_xlsx(str_c(Path,"/1_",
                                  OmicGroup,
                                  "/Features_Selection/Coefficients_lasso.xlsx"))
      # task lasso train
      df.all.train %>%
        set_task(id = "lasso",
                 target = VarY) -> task_lasso.train

      #Build singel omic model_lasso
      #lasso_predictions
      learner_lasso$predict(task_lasso.train)$response -> eSet$MulOmics[[OmicGroup]]$Models$Predictions$lasso$train_set
      learner_lasso$predict_newdata(df.all.test)$response -> eSet$MulOmics[[OmicGroup]]$Models$Predictions$lasso$test_set
      #lasso_explainer
      if(!file.exists(str_c(Path,"/1_",OmicGroup,"/Feature_Explain/Lasso"))){
        dir.create(str_c(Path,"/1_",OmicGroup,"/Feature_Explain/Lasso"))
      }
      ddpcr::quiet(
        expl_ls <- DALEX::explain(model = learner_lasso$model,
                                  data = df.all.train %>% dplyr::select(all_of(VarsX),all_of(VarsC)) %>% as.matrix(),
                                  y = df.all.train %>% dplyr::select(VarY) %>% as.matrix() %>% as.numeric(),
                                  label = "lasso"))
      expl_ls -> eSet$MulOmics[[OmicGroup]]$Models$Explainer$expl_lasso
      # lasso_Importance
      ddpcr::quiet(
        model_parts(explainer = expl_ls,
                    loss_function = loss_default(expl_ls$model_info$type),
                    B=10,
                    type = "difference") -> eSet$MulOmics[[OmicGroup]]$Models$Explainer$importance_lasso
      )
      eSet$MulOmics[[OmicGroup]]$Models$Explainer$importance_lasso %>%
        writexl::write_xlsx(stringr::str_c(Path,"/1_",
                                           OmicGroup,
                                           "/Feature_Explain/Lasso/Importance_lasso.xlsx"))

      #define benchmarking task & learners
      bm_task <- bm_task %>% append(task_lasso.train)
      bm_learners <- bm_learners %>% append(learner_lasso)
      ls_models <- ls_models %>% append(list(lasso = learner_lasso))
      ls_features <- ls_features %>% append(list(lasso = features_lasso))
    }

    if("enet" %in% SG_Lrns){
      # feature selection_en
      if (TuneMethod == "default"){
        learner_enet = lrn(str_c(task,".cv_glmnet"),
                                 predict_type = pred.type,
                                 predict_sets = c("train", "test"),
                                 id = "enet")
      }
      else{
        learner_enet = lrn(str_c(task,".glmnet"),
                                 predict_type = pred.type,
                                 predict_sets = c("train", "test"),
                                 id = "enet")
        search_space = ps(
          alpha = p_dbl(lower = 0, upper = 1),
          lambda = p_dbl(lower = 0, upper = 1)
        )
        terminator = trm("evals", n_evals = TuneNum)
        tuner = tnr(TuneMethod)
        at = AutoTuner$new(
          learner = learner_enet,
          resampling = resampling,
          measure = msr(measure_key_tune),
          search_space = search_space,
          terminator = terminator,
          tuner = tuner
        )
        lubridate::now() %>%
          stringr::str_replace_all(":",".") %>%
          stringr::str_replace_all("-",".") -> NowTime

        message(stringr::str_c("Autotunning enet Model for Feature Selection... Please be patient!",NowTime))
        eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Autotunning enet Model for Feature Selection... Please be patient!",NowTime))
        ddpcr::quiet(at$train(task0.train))

        lubridate::now() %>%
          stringr::str_replace_all(":",".") %>%
          stringr::str_replace_all("-",".") -> NowTime

        message(stringr::str_c("enet Model Autotune Accomplished!",NowTime))
        eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("enet Model Autotune Accomplished!",NowTime))
        learner_enet$param_set$values <- at$model$tuning_instance$result_learner_param_vals
      }
      learner_enet$train(task0.train)
      learner_enet$selected_features() -> features_enet
      eSet$Expo$Voca %>%
        dplyr::filter(SerialNo %in% features_enet) %>%
        writexl::write_xlsx(str_c(Path,"/1_",
                                  OmicGroup,
                                  "/Features_Selection/Selected.features_enet.xlsx"))
      # Save coefficients
      learner_enet$model %>% stats::coef(s='lambda.1se') %>% as.matrix -> Coef_enet
      Coef_enet %>%
        as_tibble() %>%
        purrr::set_names("Coef") %>%
        dplyr::mutate(SerialNo = rownames(Coef_enet)) -> eSet$MulOmics[[OmicGroup]]$Features$Coef$enet

      eSet$MulOmics[[OmicGroup]]$Features$Coef$enet %>%
        writexl::write_xlsx(str_c(Path,"/1_",
                                  OmicGroup,
                                  "/Features_Selection/Coefficients_enet.xlsx"))
      # task enet train
      df.all.train %>%
        set_task(id = "enet",
                 target = VarY) -> task_enet.train


      #Build single omic model_en
      #En_predictions
      learner_enet$predict(task_enet.train)$response -> eSet$MulOmics[[OmicGroup]]$Models$Predictions$enet$train_set
      learner_enet$predict_newdata(df.all.test)$response -> eSet$MulOmics[[OmicGroup]]$Models$Predictions$enet$test_set
      #En_explainer
      if(!file.exists(str_c(Path,"/1_",OmicGroup,"/Feature_Explain/ElasticNet"))){
        dir.create(str_c(Path,"/1_",OmicGroup,"/Feature_Explain/ElasticNet"))
      }
      ddpcr::quiet(
        expl_enet <- DALEX::explain(model = learner_enet$model,
                                          data = df.all.train %>% dplyr::select(all_of(VarsX),all_of(VarsC)) %>% as.matrix(),
                                          y = df.all.train %>% dplyr::select(VarY) %>% as.matrix() %>% as.numeric(),
                                          label = "enet"))
      expl_enet -> eSet$MulOmics[[OmicGroup]]$Models$Explainer$expl_enet
      #En_Importance
      ddpcr::quiet(
        model_parts(explainer = expl_enet,
                    loss_function = loss_default(expl_enet$model_info$type),
                    B=10,
                    type = "difference") -> eSet$MulOmics[[OmicGroup]]$Models$Explainer$importance_enet
      )
      eSet$MulOmics[[OmicGroup]]$Models$Explainer$importance_enet %>%
        writexl::write_xlsx(stringr::str_c(Path,"/1_",
                                           OmicGroup,
                                           "/Feature_Explain/ElasticNet/Importance_enet.xlsx"))
      #define benchmarking tasks &learners
      bm_task <- bm_task %>% append(task_enet.train)
      bm_learners <- bm_learners %>% append(learner_enet)
      ls_models <- ls_models %>% append(list(enet = learner_enet))
      ls_features <- ls_features %>% append(list(enet = features_enet))
    }

    if("rf" %in% SG_Lrns){
      # feature selection_rf
      if (TuneMethod == "default"){
        learner = lrn(str_c(task,".ranger"),
                      predict_type = pred.type)
      }else{
        learner = lrn(str_c(task,".ranger"),
                      predict_type = pred.type)
        search_space = ps(
          max.depth = p_int(lower = 6, upper = 100),
          mtry.ratio = p_dbl(lower = 0.3, upper = 0.7),
          num.trees = p_int(lower = 10, upper = 500)
        )
        terminator = trm("evals", n_evals = TuneNum)
        tuner = tnr(TuneMethod)
        at = AutoTuner$new(
          learner = learner,
          resampling = resampling,
          measure = msr(measure_key_tune),
          search_space = search_space,
          terminator = terminator,
          tuner = tuner
        )

        lubridate::now() %>%
          stringr::str_replace_all(":",".") %>%
          stringr::str_replace_all("-",".") -> NowTime

        message(stringr::str_c("Autotunning rf Model for Feature Selection... Please be patient!",NowTime))
        eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Autotunning rf Model for Feature Selection... Please be patient!",NowTime))
        ddpcr::quiet(at$train(task0.train))

        lubridate::now() %>%
          stringr::str_replace_all(":",".") %>%
          stringr::str_replace_all("-",".") -> NowTime

        message(stringr::str_c("rf Model Autotune Accomplished!",NowTime))
        eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("rf Model Autotune Accomplished!",NowTime))
        learner$param_set$values <- at$model$tuning_instance$result_learner_param_vals # set paramete
      }
      learner$param_set$values$importance <- "permutation"
      learner$train(task0.train)
      learner$importance() %>% sort(decreasing=T) -> importance_rf
      # Save feature importance
      importance_rf %>% names() %>% tibble(SerialNo = .) %>%
        dplyr::mutate(importance = importance_rf) %>%
        dplyr::filter(importance > 0)  %>%
        dplyr::mutate(importance_perct = map_dbl(importance,
                                          ~(./sum(importance))),
               importance_perct_cum = cumsum(importance_perct)) -> eSet$MulOmics[[OmicGroup]]$Features$feature_importance$rf

      eSet$MulOmics[[OmicGroup]]$Features$feature_importance$rf %>%
        dplyr::left_join(eSet$Expo$Voca %>% dplyr::select(SerialNo,FullName),
                  by = "SerialNo") %>%
        writexl::write_xlsx(str_c(Path,"/1_",
                                  OmicGroup,
                                  "/Features_Selection/Importance_rf.xlsx"))
      eSet$MulOmics[[OmicGroup]]$Features$feature_importance$rf %>%
        dplyr::filter(importance_perct_cum <= VarsImpThr) %>%
        dplyr::select(SerialNo) %>% as.matrix() %>% as.vector() -> features_rf # features selection

      eSet$Expo$Voca %>%
        dplyr::filter(SerialNo %in% features_rf) %>%
        writexl::write_xlsx(str_c(Path,"/1_",
                                  OmicGroup,
                                  "/Features_Selection/Selected.features_rf.xlsx"))
      # task ranger train
      df.all.train %>%
        dplyr::select(all_of(VarY),
                      all_of(features_rf)) %>%
        set_task(id = "rf",
                 target = VarY) -> task_rf.train

      # task ranger test
      df.all.test %>%
        dplyr::select(all_of(VarY),
                      all_of(features_rf)) -> newdt_rf.test

      #Build single omic model_rf
      if (TuneMethod == "default"){
        learner_rf <- lrn(str_c(task,".ranger"),
                           predict_type = pred.type,
                           predict_sets = c("train", "test"),
                           id = "rf")
      }else{
        learner_rf <- lrn(str_c(task,".ranger"),
                           predict_type = pred.type,
                           predict_sets = c("train", "test"),
                           id = "rf")
        # auto-tune ranger
        search_space = ps(
          max.depth = p_int(lower = 6, upper = 100),
          mtry.ratio = p_dbl(lower = 0.3, upper = 0.7),
          num.trees = p_int(lower = 10, upper = 500)
        )
        terminator = trm("evals", n_evals = TuneNum)
        tuner = tnr(TuneMethod)
        at_rf = AutoTuner$new(
          learner = learner_rf,
          resampling = resampling,
          measure = msr(measure_key_tune),
          search_space = search_space,
          terminator = terminator,
          tuner = tuner
        )

        lubridate::now() %>%
          stringr::str_replace_all(":",".") %>%
          stringr::str_replace_all("-",".") -> NowTime

        message(stringr::str_c("Autotunning rf Model for Final Model.. Please be patient!",NowTime))
        eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Autotunning rf Model for Final Model.. Please be patient!",NowTime))
        ddpcr::quiet(at_rf$train(task_rf.train))

        lubridate::now() %>%
          stringr::str_replace_all(":",".") %>%
          stringr::str_replace_all("-",".") -> NowTime

        message(stringr::str_c("rf Model Autotune Accomplished!",NowTime))
        eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("rf Model Autotune Accomplished!",NowTime))
        learner_rf$param_set$values <- at_rf$model$tuning_instance$result_learner_param_vals
      }
      #rf_predictions
      learner_rf$train(task_rf.train)
      learner_rf$predict(task_rf.train)$response -> eSet$MulOmics[[OmicGroup]]$Models$Predictions$rf$train_set
      learner_rf$predict_newdata(newdt_rf.test)$response -> eSet$MulOmics[[OmicGroup]]$Models$Predictions$rf$test_set
      #rf_explainer
      if(!file.exists(str_c(Path,"/1_",OmicGroup,"/Feature_Explain/RandomForest"))){
        dir.create(str_c(Path,"/1_",OmicGroup,"/Feature_Explain/RandomForest"))
      }
      ddpcr::quiet(
        expl_rf <- DALEX::explain(model = learner_rf$model,
                                  data = df.all.train %>% dplyr::select(features_rf) %>% as.matrix(),
                                  y = df.all.train %>% dplyr::select(VarY) %>% as.matrix() %>% as.numeric(),
                                  label = "rf"))

      expl_rf -> eSet$MulOmics[[OmicGroup]]$Models$Explainer$expl_rf
      #rf_Importance
      ddpcr::quiet(
        model_parts(explainer = expl_rf,
                    loss_function = loss_default(expl_rf$model_info$type),
                    B=10,
                    type = "difference") -> eSet$MulOmics[[OmicGroup]]$Models$Explainer$importance_rf
      )

      eSet$MulOmics[[OmicGroup]]$Models$Explainer$importance_rf %>%
        writexl::write_xlsx(stringr::str_c(Path,"/1_",
                                           OmicGroup,
                                           "/Feature_Explain/RandomForest/Importance_rf.xlsx"))
      #define benchmarking tasks &learners
      bm_task <- bm_task %>% append(task_rf.train)
      bm_learners <- bm_learners %>% append(learner_rf)
      ls_models <- ls_models %>% append(list(rf = learner_rf))
      ls_features <- ls_features %>% append(list(rf = features_rf))
    }

    if("xgboost" %in% SG_Lrns){
      # feature selection_xgboost
      if (TuneMethod == "default"){
        learner = lrn(str_c(task,".xgboost"),
                      predict_type = pred.type)
        learner$param_set$values$eta = 0.1
      }
      else{
        learner = lrn(str_c(task,".xgboost"),
                      predict_type = pred.type)
        learner$param_set$values$eta = 0.1
        search_space = ps(
          subsample = p_dbl(lower = 0.5, upper = 1),
          colsample_bytree = p_dbl(lower = 0.5, upper = 1),
          max_depth = p_int(lower = 3, upper = 10),
          nrounds = p_int(lower = 2, upper = 200)
        )
        terminator = trm("evals", n_evals = TuneNum)
        tuner = tnr(TuneMethod)
        at = AutoTuner$new(
          learner = learner,
          resampling = resampling,
          measure = msr(measure_key_tune),
          search_space = search_space,
          terminator = terminator,
          tuner = tuner
        )

        lubridate::now() %>%
          stringr::str_replace_all(":",".") %>%
          stringr::str_replace_all("-",".") -> NowTime

        message(stringr::str_c("Autotunning xgboost Model for Feature Selection... Please be patient!",NowTime))
        eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Autotunning xgboost Model for Feature Selection... Please be patient!",NowTime))
        ddpcr::quiet(at$train(task0.train))

        lubridate::now() %>%
          stringr::str_replace_all(":",".") %>%
          stringr::str_replace_all("-",".") -> NowTime

        message(stringr::str_c("xgboost Model Autotune Accomplished!",NowTime))
        eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("xgboost Model Autotune Accomplished!",NowTime))
        learner$param_set$values <- at$model$tuning_instance$result_learner_param_vals # set parameter
      }
      learner$train(task0.train)
      learner$importance() %>% sort(decreasing=T) -> importance_xgboost
      # Save feature importance
      importance_xgboost %>% names() %>% tibble(SerialNo = .) %>%
        dplyr::mutate(importance = importance_xgboost) %>%
        dplyr::filter(importance > 0)  %>%
        dplyr::mutate(importance_perct = map_dbl(importance,
                                          ~(./sum(importance))),
               importance_perct_cum = cumsum(importance_perct)) -> eSet$MulOmics[[OmicGroup]]$Features$feature_importance$xgboost

      eSet$MulOmics[[OmicGroup]]$Features$feature_importance$xgboost %>%
        dplyr::left_join(eSet$Expo$Voca %>% dplyr::select(SerialNo,FullName),
                  by = "SerialNo") %>%
        writexl::write_xlsx(str_c(Path,"/1_",
                                  OmicGroup,
                                  "/Features_Selection/Importance_xgboost.xlsx"))

      eSet$MulOmics[[OmicGroup]]$Features$feature_importance$xgboost %>%
        dplyr::filter(importance_perct_cum <= VarsImpThr) %>%
        dplyr::select(SerialNo) %>% as.matrix() %>% as.vector() -> features_xgboost # features selection

      eSet$Expo$Voca %>%
        dplyr::filter(SerialNo %in% features_xgboost) %>%
        writexl::write_xlsx(str_c(Path,"/1_",
                                  OmicGroup,
                                  "/Features_Selection/Selected.features_xgboost.xlsx"))
      # task xgboost train
      df.all.train %>%
        dplyr::select(all_of(VarY),
                      all_of(features_xgboost)) %>%
        set_task(id = "xgboost",
                 target = VarY) -> task_xgboost.train

      # task xgboost test
      df.all.test %>%
        dplyr::select(all_of(VarY),
                      all_of(features_xgboost)) -> newdt_xgboost.test

      #Build singel omic model_xgboost
      if (TuneMethod == "default"){
        learner_xgboost <- lrn(str_c(task,".xgboost"),
                                predict_type = pred.type,
                                predict_sets = c("train", "test"),
                                id = "xgboost")
      }else{
        # auto-tune xgboost
        learner_xgboost <- lrn(str_c(task,".xgboost"),
                                predict_type = pred.type,
                                predict_sets = c("train", "test"),
                                id = "xgboost")
        learner_xgboost$param_set$values$eta = 0.1
        search_space = ps(
          subsample = p_dbl(lower = 0.5, upper = 1),
          colsample_bytree = p_dbl(lower = 0.5, upper = 1),
          max_depth = p_int(lower = 3, upper = 10),
          nrounds = p_int(lower = 2, upper = 200)
        )
        terminator = trm("evals", n_evals = TuneNum)
        tuner = tnr(TuneMethod)
        at_xgboost = AutoTuner$new(
          learner = learner_xgboost,
          resampling = resampling,
          measure = msr(measure_key_tune),
          search_space = search_space,
          terminator = terminator,
          tuner = tuner
        )

        lubridate::now() %>%
          stringr::str_replace_all(":",".") %>%
          stringr::str_replace_all("-",".") -> NowTime

        message(stringr::str_c("Autotunning xgboost Model for Final Model... Please be patient!",NowTime))
        eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Autotunning xgboost Model for Final Model... Please be patient!",NowTime))
        ddpcr::quiet(at_xgboost$train(task_xgboost.train))

        lubridate::now() %>%
          stringr::str_replace_all(":",".") %>%
          stringr::str_replace_all("-",".") -> NowTime

        message(stringr::str_c("xgboost Model Autotune Accomplished!",NowTime))
        eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("xgboost Model Autotune Accomplished!",NowTime))
        learner_xgboost$param_set$values <- at_xgboost$model$tuning_instance$result_learner_param_vals
      }
      #xgboost_predictions
      learner_xgboost$train(task_xgboost.train)
      learner_xgboost$predict(task_xgboost.train)$response -> eSet$MulOmics[[OmicGroup]]$Models$Predictions$xgboost$train_set
      learner_xgboost$predict_newdata(newdt_xgboost.test)$response -> eSet$MulOmics[[OmicGroup]]$Models$Predictions$xgboost$test_set
      #xgboost_explainer
      if(!file.exists(str_c(Path,"/1_",OmicGroup,"/Feature_Explain/Xgboost"))){
        dir.create(str_c(Path,"/1_",OmicGroup,"/Feature_Explain/Xgboost"))
      }
      ddpcr::quiet(
        expl_xgboost <- DALEX::explain(model = learner_xgboost$model,
                                       data = df.all.train %>% dplyr::select(learner_xgboost$model$feature_names) %>% as.matrix(),
                                       y = df.all.train %>% dplyr::select(VarY) %>% as.matrix() %>% as.numeric(),
                                       label = "xgboost"))
      expl_xgboost -> eSet$MulOmics[[OmicGroup]]$Models$Explainer$expl_xgboost
      #xgboost_Importance
      ddpcr::quiet(
        model_parts(explainer = expl_xgboost,
                    loss_function = loss_default(expl_xgboost$model_info$type),
                    B=10,
                    type = "difference") -> eSet$MulOmics[[OmicGroup]]$Models$Explainer$importance_xgboost)
      eSet$MulOmics[[OmicGroup]]$Models$Explainer$importance_xgboost %>%
        writexl::write_xlsx(stringr::str_c(Path,"/1_",
                                           OmicGroup,
                                           "/Feature_Explain/Xgboost/Importance_xgboost.xlsx"))
      #define benchmarking tasks &learners
      bm_task <- bm_task %>% append(task_xgboost.train)
      bm_learners <- bm_learners %>% append(learner_xgboost)
      ls_models <- ls_models %>% append(list(xgboost = learner_xgboost))
      ls_features <- ls_features %>% append(list(xgboost = features_xgboost))
    }

    # save features selected & models
    ls_features -> eSet$MulOmics[[OmicGroup]]$Features$features_selected
    ls_models -> eSet$MulOmics[[OmicGroup]]$Models$learners

    # benchmarking
    design = benchmark_grid(
      tasks = bm_task,
      learners = bm_learners,
      resamplings = resampling)

    lubridate::now() %>%
      stringr::str_replace_all(":",".") %>%
      stringr::str_replace_all("-",".") -> NowTime

    message(stringr::str_c("Running Benchmark...Please be Patient",NowTime))
    eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Running Benchmark...Please be Patient",NowTime))
    ddpcr::quiet(benchmark(design[map_chr(design$task,~.$id)==map_chr(design$learner,~.$id)]) -> eSet$MulOmics[[OmicGroup]]$Models$Measures$bmr)

    lubridate::now() %>%
      stringr::str_replace_all(":",".") %>%
      stringr::str_replace_all("-",".") -> NowTime

    message(stringr::str_c("Benchmark Accomplished!",NowTime))
    eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Benchmark Accomplished!",NowTime))
    measures_bmr = list(msr(measure_key, predict_sets = "train", id = str_c(measure_id,"_train")),
                        msr(measure_key, id =str_c(measure_id,"_test") ))
    eSet$MulOmics[[OmicGroup]]$Models$Measures$bmr$aggregate(measures_bmr) %>%
      dplyr::mutate(learners = SG_Lrns,
             RsmpMethod = map2_chr(resampling_id,
                                   iters,
                                   ~str_c(.x,"-",.y))) %>%
      dplyr::select(learners,
                    RsmpMethod,
                    str_c(measure_id,"_train"),
                    str_c(measure_id,"_test")) -> eSet$MulOmics[[OmicGroup]]$Models$Measures$stat

    eSet$MulOmics[[OmicGroup]]$Models$Measures$stat %>%
      writexl::write_xlsx(str_c(Path,"/1_",
                                OmicGroup,
                                "/Model_Summary/Measures_stat.xlsx"))

    lubridate::now() %>%
      stringr::str_replace_all(":",".") %>%
      stringr::str_replace_all("-",".") -> NowTime

    message(stringr::str_c("Machine learning models for ",OmicGroup," completed!",NowTime))
    eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Machine learning models for ",OmicGroup," completed!",NowTime))
    return(eSet)
  }
  # Define SG process ---------------------------------------------------------
  SG.MulOmics <- function(SG_Lrn,
                          VarY,
                          TuneMethod,
                          TuneNum,
                          task,
                          pred.type,
                          measure_key,
                          measure_key_tune,
                          measure_id,
                          svm.type,
                          set_task,
                          resampling){

    if(!file.exists(str_c(Path,"/2_SG/Model_Summary"))){
      dir.create(str_c(Path,"/2_SG/Model_Summary"))
    }
    if(!file.exists(str_c(Path,"/2_SG/Viz_InterOmic"))){
      dir.create(str_c(Path,"/2_SG/Viz_InterOmic"))
    }
    if(!file.exists(str_c(Path,"/2_SG/Viz_Prediction"))){
      dir.create(str_c(Path,"/2_SG/Viz_Prediction"))
    }

    lubridate::now() %>%
      stringr::str_replace_all(":",".") %>%
      stringr::str_replace_all("-",".") -> NowTime

    message(stringr::str_c("Step2: SG by ",SG_Lrn," under way...",NowTime))
    eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Step2: SG by ",SG_Lrn," under way...",NowTime))
    # define data
    eSet$Expo$Data %>%
      dplyr::filter(Group == "train") %>%
      dplyr::select(all_of(VarY)) -> df.Y.train
    eSet$Expo$Data %>%
      dplyr::filter(Group == "test") %>%
      dplyr::select(all_of(VarY)) -> df.Y.test
    # train SG model
    lubridate::now() %>%
      stringr::str_replace_all(":",".") %>%
      stringr::str_replace_all("-",".") -> NowTime

    message(stringr::str_c("Trainning Final Models...Please be Patient!",NowTime))
    eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Trainning Final Models...Please be Patient!",NowTime))
    # define SG learner
    switch (SG_Lrn,
            "lasso" = {
              learner = lrn(str_c(task,".cv_glmnet"),
                            predict_type = pred.type,
                            predict_sets = c("train", "test"),
                            id = "lasso")
              learner$param_set$values = list(alpha = 1)
            },
            "enet" = {
              if (TuneMethod == "default"){
                learner = lrn(str_c(task,".cv_glmnet"),
                              predict_type = pred.type,
                              predict_sets = c("train", "test"),
                              id = "enet")
              }
              else{
                search_space = ps(
                  alpha = p_dbl(lower = 0, upper = 1),
                  lambda = p_dbl(lower = 0, upper = 1)
                )
                terminator = trm("evals", n_evals = TuneNum)
                tuner = tnr(TuneMethod)
                learner = AutoTuner$new(
                  learner = lrn(str_c(task,".glmnet"),
                                predict_type = pred.type,
                                predict_sets = c("train", "test"),
                                id = "enet"),
                  resampling = resampling,
                  measure = msr(measure_key_tune),
                  search_space = search_space,
                  terminator = terminator,
                  tuner = tuner)}
            },
            "rf" = {
              if (TuneMethod == "default"){
                learner = lrn(str_c(task,".ranger"),
                              predict_type = pred.type,
                              predict_sets = c("train", "test"),
                              id = "rf")}else{
                search_space = ps(
                  max.depth = p_int(lower = 6, upper = 100),
                  mtry.ratio = p_dbl(lower = 0.3, upper = 0.7),
                  num.trees = p_int(lower = 10, upper = 500)
                )
                terminator = trm("evals", n_evals = TuneNum)
                tuner = tnr(TuneMethod)
                learner = AutoTuner$new(
                  learner = lrn(str_c(task,".ranger"),
                                predict_type = pred.type,
                                predict_sets = c("train", "test"),
                                id = "rf"),
                  resampling = resampling,
                  measure = msr(measure_key_tune),
                  search_space = search_space,
                  terminator = terminator,
                  tuner = tuner)
                }

            },
            "xgboost" = {
              if (TuneMethod == "default"){
                learner = lrn(str_c(task,".xgboost"),
                              predict_type = pred.type,
                              predict_sets = c("train", "test"),
                              id = "xgboost")}
              else{
                search_space = ps(
                  subsample = p_dbl(lower = 0.5, upper = 1),
                  colsample_bytree = p_dbl(lower = 0.5, upper = 1),
                  max_depth = p_int(lower = 3, upper = 10),
                  nrounds = p_int(lower = 2, upper = 200)
                )
                terminator = trm("evals", n_evals = TuneNum)
                tuner = tnr(TuneMethod)
                learner_xgb = lrn(str_c(task,".xgboost"),
                                  predict_type = pred.type,
                                  predict_sets = c("train", "test"),
                                  id = "xgboost")
                learner_xgb$param_set$values$eta = 0.1
                learner = AutoTuner$new(
                  learner = learner_xgb,
                  resampling = resampling,
                  measure = msr(measure_key_tune),
                  search_space = search_space,
                  terminator = terminator,
                  tuner = tuner)}

            },
    )


    #train-prediction-compare y&y_pred
    SG_bm_task = c()
    SG_ls_models = list()

    if("lasso" %in% SG_Lrns){
      #define SG task
      ddpcr::quiet(
        map_dfc(eSet$MulOmics$OmicGroup.all,
                ~(as.numeric(as.character(eSet$MulOmics[[.]]$Models$Predictions$lasso$train_set)))) %>%
          purrr::set_names(str_c(eSet$MulOmics$OmicGroup.all,".","pred")) %>%
          bind_cols(Y = df.Y.train) %>%
          set_task(target = VarY,
                   id = "Step1 by lasso") -> train.task.SG.lasso)

      ddpcr::quiet(
        map_dfc(eSet$MulOmics$OmicGroup.all,
                ~(as.numeric(as.character(eSet$MulOmics[[.]]$Models$Predictions$lasso$test_set)))) %>%
          purrr::set_names(str_c(eSet$MulOmics$OmicGroup.all,".","pred")) %>%
          bind_cols(Y = df.Y.test) -> newdt.SG.lasso)

      #train_prediciton
      ddpcr::quiet(learner$train(train.task.SG.lasso) -> SG_from_lasso)
      SG_from_lasso$predict(train.task.SG.lasso)$response -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by lasso"]]$train_set
      SG_from_lasso$predict_newdata(newdt.SG.lasso)$response -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by lasso"]]$test_set

      #compare y&y_pred
      bind_cols(
        df.Y.train %>% purrr::set_names("True.Y.Train"),
        Pred.Y.Train = eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by lasso"]]$train_set
      ) -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by lasso"]]$train
      eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by lasso"]]$train %>%
        writexl::write_xlsx(str_c(Path,"/",
                                  "2_SG/Viz_Prediction/",
                                  "Step1 by lasso Step2 by ",
                                  SG_Lrn,
                                  "_train.xlsx"))
      bind_cols(
        df.Y.test %>% purrr::set_names("True.Y.Test"),
        Pred.Y.Test = eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by lasso"]]$test_set
      ) -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by lasso"]]$test
      eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by lasso"]]$test %>%
        writexl::write_xlsx(str_c(Path,"/",
                                  "2_SG/Viz_Prediction/",
                                  "Step1 by lasso Step2 by ",
                                  SG_Lrn,
                                  "_test.xlsx"))
      #define SG benchmarking tasks
      SG_bm_task = SG_bm_task %>% append(train.task.SG.lasso)
      SG_ls_models = SG_ls_models %>% append(list(lasso = SG_from_lasso))
    }

    if("enet" %in% SG_Lrns){
      #define SG task
      ddpcr::quiet(
        map_dfc(eSet$MulOmics$OmicGroup.all,
                ~(as.numeric(as.character(eSet$MulOmics[[.]]$Models$Predictions$enet$train_set)))) %>%
          purrr::set_names(str_c(eSet$MulOmics$OmicGroup.all,".","pred")) %>%
          bind_cols(Y = df.Y.train) %>%
          set_task(target = VarY,
                   id = "Step1 by enet") -> train.task.SG.enet)

      ddpcr::quiet(
        map_dfc(eSet$MulOmics$OmicGroup.all,
                ~(as.numeric(as.character(eSet$MulOmics[[.]]$Models$Predictions$enet$test_set)))) %>%
          purrr::set_names(str_c(eSet$MulOmics$OmicGroup.all,".","pred")) %>%
          bind_cols(Y = df.Y.test) -> newdt.SG.enet)

      #train_prediciton
      ddpcr::quiet(learner$train(train.task.SG.enet) -> SG_from_enet)
      SG_from_enet$predict(train.task.SG.enet)$response -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by enet"]]$train_set
      SG_from_enet$predict_newdata(newdt.SG.enet)$response -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by enet"]]$test_set

      #compare y&y_pred
      bind_cols(
        df.Y.train %>% purrr::set_names("True.Y.Train"),
        Pred.Y.Train = eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by enet"]]$train_set
      ) -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by enet"]]$train
      eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by enet"]]$train %>%
        writexl::write_xlsx(str_c(Path,"/",
                                  "2_SG/Viz_Prediction/",
                                  "Step1 by enet Step2 by ",
                                  SG_Lrn,
                                  "_train.xlsx"))
      bind_cols(
        df.Y.test %>% purrr::set_names("True.Y.Test"),
        Pred.Y.Test = eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by enet"]]$test_set
      ) -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by enet"]]$test
      eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by enet"]]$test %>%
        writexl::write_xlsx(str_c(Path,"/",
                                  "2_SG/Viz_Prediction/",
                                  "Step1 by enet Step2 by ",
                                  SG_Lrn,
                                  "_test.xlsx"))
      #define SG benchmarking tasks
      SG_bm_task = SG_bm_task %>% append(train.task.SG.enet)
      SG_ls_models = SG_ls_models %>% append(list(enet = SG_from_enet))
    }

    if("rf" %in% SG_Lrns){
      #define SG task
      ddpcr::quiet(
        map_dfc(eSet$MulOmics$OmicGroup.all,
                ~(as.numeric(as.character(eSet$MulOmics[[.]]$Models$Predictions$rf$train_set)))) %>%
          purrr::set_names(str_c(eSet$MulOmics$OmicGroup.all,".","pred")) %>%
          bind_cols(Y = df.Y.train) %>%
          set_task(target = VarY,
                   id = "Step1 by rf") -> train.task.SG.rf)

      ddpcr::quiet(
        map_dfc(eSet$MulOmics$OmicGroup.all,
                ~(as.numeric(as.character(eSet$MulOmics[[.]]$Models$Predictions$rf$test_set)))) %>%
          purrr::set_names(str_c(eSet$MulOmics$OmicGroup.all,".","pred")) %>%
          bind_cols(Y = df.Y.test) -> newdt.SG.rf)

      #train_prediciton
      ddpcr::quiet(learner$train(train.task.SG.rf) -> SG_from_rf)
      SG_from_rf$predict(train.task.SG.rf)$response -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by rf"]]$train_set
      SG_from_rf$predict_newdata(newdt.SG.rf)$response -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by rf"]]$test_set

      #compare y&y_pred
      bind_cols(
        df.Y.train %>% purrr::set_names("True.Y.Train"),
        Pred.Y.Train = eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by rf"]]$train_set
      ) -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by rf"]]$train
      eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by rf"]]$train %>%
        writexl::write_xlsx(str_c(Path,"/",
                                  "2_SG/Viz_Prediction/",
                                  "Step1 by rf Step2 by ",
                                  SG_Lrn,
                                  "_train.xlsx"))
      bind_cols(
        df.Y.test %>% purrr::set_names("True.Y.Test"),
        Pred.Y.Test = eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by rf"]]$test_set
      ) -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by rf"]]$test
      eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by rf"]]$test %>%
        writexl::write_xlsx(str_c(Path,"/",
                                  "2_SG/Viz_Prediction/",
                                  "Step1 by rf Step2 by ",
                                  SG_Lrn,
                                  "_test.xlsx"))
      #define SG benchmarking tasks
      SG_bm_task = SG_bm_task %>% append(train.task.SG.rf)
      SG_ls_models = SG_ls_models %>% append(list(rf = SG_from_rf))
    }

    if("xgboost" %in% SG_Lrns){
      #define SG task
      ddpcr::quiet(
        map_dfc(eSet$MulOmics$OmicGroup.all,
                ~(as.numeric(as.character(eSet$MulOmics[[.]]$Models$Predictions$xgboost$train_set)))) %>%
          purrr::set_names(str_c(eSet$MulOmics$OmicGroup.all,".","pred")) %>%
          bind_cols(Y = df.Y.train) %>%
          set_task(target = VarY,
                   id = "Step1 by xgboost") -> train.task.SG.xgboost)

      ddpcr::quiet(
        map_dfc(eSet$MulOmics$OmicGroup.all,
                ~(as.numeric(as.character(eSet$MulOmics[[.]]$Models$Predictions$xgboost$test_set)))) %>%
          purrr::set_names(str_c(eSet$MulOmics$OmicGroup.all,".","pred")) %>%
          bind_cols(Y = df.Y.test) -> newdt.SG.xgboost)

      #train_prediciton
      ddpcr::quiet(learner$train(train.task.SG.xgboost) -> SG_from_xgboost)
      SG_from_xgboost$predict(train.task.SG.xgboost)$response -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by xgboost"]]$train_set
      SG_from_xgboost$predict_newdata(newdt.SG.xgboost)$response -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by xgboost"]]$test_set

      #compare y&y_pred
      bind_cols(
        df.Y.train %>% purrr::set_names("True.Y.Train"),
        Pred.Y.Train = eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by xgboost"]]$train_set
      ) -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by xgboost"]]$train
      eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by xgboost"]]$train %>%
        writexl::write_xlsx(str_c(Path,"/",
                                  "2_SG/Viz_Prediction/",
                                  "Step1 by xgboost Step2 by ",
                                  SG_Lrn,
                                  "_train.xlsx"))
      bind_cols(
        df.Y.test %>% purrr::set_names("True.Y.Test"),
        Pred.Y.Test = eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$predictions[["Step1 by xgboost"]]$test_set
      ) -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by xgboost"]]$test
      eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$y_y.pred[["Step1 by xgboost"]]$test %>%
        writexl::write_xlsx(str_c(Path,"/",
                                  "2_SG/Viz_Prediction/",
                                  "Step1 by xgboost Step2 by ",
                                  SG_Lrn,
                                  "_test.xlsx"))
      # define SG benchmarking tasks
      SG_bm_task = SG_bm_task %>% append(train.task.SG.xgboost)
      SG_ls_models = SG_ls_models %>% append(list(xgboost = SG_from_xgboost))
    }

    # save SG_models
    SG_ls_models -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$learners

    # benchmark
    design = benchmark_grid(
      tasks = SG_bm_task,
      learners = learner,
      resamplings = resampling
    )

    lubridate::now() %>%
      stringr::str_replace_all(":",".") %>%
      stringr::str_replace_all("-",".") -> NowTime

    message(stringr::str_c("Running Benchmark...This Step Will Take Lots of Time. Please be Patient!",NowTime))
    eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Running Benchmark...This Step Will Take Lots of Time. Please be Patient!",NowTime))
    ddpcr::quiet(benchmark(design) -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$bmr)

    lubridate::now() %>%
      stringr::str_replace_all(":",".") %>%
      stringr::str_replace_all("-",".") -> NowTime

    message(stringr::str_c("Benchmark Accomplished!",NowTime))
    eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Benchmark Accomplished!",NowTime))
    measures_bmr = list(msr(measure_key, predict_sets = "train", id = str_c(measure_id,"_train")),
                        msr(measure_key, id = str_c(measure_id,"_test")))

    eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$bmr$aggregate(measures_bmr) %>%
      dplyr::mutate(Step2 = rep(SG_Lrn,length(learner_id)),
             Step1 = task_id,
             resampling.method = map2_chr(resampling_id,
                                          iters,
                                          ~str_c(.x,"-",.y))) %>%
      dplyr::select(Step1,
                    Step2,
                    resampling.method,
                    str_c(measure_id,"_train"),
                    str_c(measure_id,"_test")) -> eSet$MulOmics$SG[[str_c("Step2 by ",SG_Lrn)]]$measures$stat

    lubridate::now() %>%
      stringr::str_replace_all(":",".") %>%
      stringr::str_replace_all("-",".") -> NowTime

    message(stringr::str_c("Step 2: SG by ",SG_Lrn," Accomplished!",NowTime))
    eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Step 2: SG by ",SG_Lrn," Accomplished!",NowTime))

    return(eSet)
  }
  # Define single Y process ---------------------------------------------------------
  single.Y = function(VarY,
                      VarsC,
                      Var.type,
                      SG_Lrns,
                      resampling){
    # define task type
    switch(Var.type,
           "factor"={
             task = "classif"
             pred.type = "prob"
             measure_key = "classif.acc"
             measure_key_tune = "classif.acc"
             measure_id = "acc"
             svm.type = "C-classification"
             set_task = function(...){as_task_classif(...)}},
           "numeric"={
             task = "regr"
             pred.type = "response"
             measure_key = "regr.rsq"
             measure_key_tune = "regr.mse"
             measure_id = "rsq"
             svm.type = "eps-regression"
             set_task = function(...){as_task_regr(...)}}
    )

    # Map single omics ---------------------------------------------------------
    map(Groups,
        single.omics,
        VarY = VarY,
        VarsC = VarsC,
        SG_Lrns = SG_Lrns,
        TuneMethod = TuneMethod,
        TuneNum = TuneNum,
        task = task,
        pred.type,
        measure_key = measure_key,
        measure_key_tune = measure_key_tune,
        measure_id = measure_id,
        set_task = set_task,
        resampling = resampling)

    # Map stacked Generalization ---------------------------------------------------------
    if(!file.exists(str_c(Path,"/2_SG"))){
      dir.create(str_c(Path,"/2_SG"))
    }
    lubridate::now() %>%
      stringr::str_replace_all(":",".") %>%
      stringr::str_replace_all("-",".") -> NowTime
    message(stringr::str_c("Folder for Step2: SG has been created!",NowTime))
    eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("Folder for Step2: SG has been created!",NowTime))

    map(SG_Lrns,
        SG.MulOmics,
        VarY = VarY,
        TuneMethod = TuneMethod,
        TuneNum = TuneNum,
        task = task,
        pred.type,
        measure_key = measure_key,
        measure_key_tune = measure_key_tune,
        measure_id = measure_id,
        svm.type = svm.type,
        set_task = set_task,
        resampling = resampling)

    # benchmark result
    map_dfr(eSet$MulOmics$SG,
            ~.$measures$stat) %>%
      writexl::write_xlsx(stringr::str_c(Path,"/",
                                         "2_SG/Model_Summary/",
                                         "Model assessment.xlsx"))

    CountNode <- function(Lrn,
                          Groups){
      map(Groups,
          ~eSet$MulOmics[[.]]$Features$features_selected[[Lrn]]) %>%
        unlist() %>% length()
    }

    tibble(Learners = SG_Lrns) %>%
      mutate(NodeNum = map_dbl(Learners,
                           ~CountNode(.,
                                      Groups = Groups))) -> eSet$MulOmics$Max_NodeNum
    message(stringr::str_c("All Data for ", VarY, " Saved!",NowTime))
    eSet$ExcecutionLog  <- eSet$AddLog(stringr::str_c("All Data for ", VarY, " Saved!",NowTime))
  }
  # define Y
  eSet$Expo$Data %>%
    dplyr::select(all_of(VarsY)) %>% as_vector() %>% class() -> Var.type

  # Define resampling ---------------------------------------------------------
  switch (RsmpMethod,
          "cv" = {resampling = rsmp("cv",
                                    folds = Folds)},
          "loo" = {resampling = rsmp("loo")},
          "bootstrap" = {resampling = rsmp("bootstrap",
                                           ratio = Ratio,
                                           repeats = Repeats)},
          "holdout" = {resampling = rsmp("holdout",
                                         ratio = Ratio)}
  )
  # Run Y ---------------------------------------------------------
  single.Y(VarY = VarsY,
           VarsC = VarsC,
           Var.type = Var.type,
           SG_Lrns = SG_Lrns,
           resampling = resampling)

  eSet$MulOmics$Max_NodeNum %>%
    data.table::fwrite(stringr::str_c(eSet$FileDirOut,"/2_SG/Model_Summary/Node number.csv"))
  # Viz measure
  VizMsr <- function(SGer,
                     eSet,
                     VarsY){
    Var.type <- eSet$Expo$Data[[VarsY]] %>% class()
    switch(Var.type,
           "factor"={measure_key = "classif.acc"},
           "numeric"={measure_key = "regr.rsq"}
    )
    eSet$MulOmics$SG[[SGer]]$bmr %>%
      autoplot(type = 'boxplot',
               measure = msr(measure_key)) -> SGboxplot
    SGboxplot$facet$params$nrow = 1
    return(SGboxplot)
  }
  Path = stringr::str_c(eSet$FileDirOut)
  map(eSet$MulOmics$SG %>% names,
      VizMsr,
      eSet = eSet,
      VarsY = VarsY) %>%
    gridExtra::marrangeGrob(nrow = eSet$MulOmics$SG %>% names() %>% length(),
                            ncol = 1) %>%
    ggplot2::ggsave(filename = str_c(Path,"/2_SG/Model_Summary/Model assessment_boxplot.png"),
                    width = 10,
                    height = 3.5*length(eSet$MulOmics$SG %>% names()))

  map(eSet$MulOmics$SG %>% names,
      VizMsr,
      eSet = eSet,
      VarsY = VarsY) %>%
    gridExtra::marrangeGrob(nrow = eSet$MulOmics$SG %>% names() %>% length(),
                            ncol = 1) %>%
    ggplot2::ggsave(filename = str_c(Path,"/2_SG/Model_Summary/Model assessment_boxplot.svg"),
                    width = 10,
                    height = 3.5*length(eSet$MulOmics$SG %>% names()))


  # save
  eSet$RCommandLog <- eSet$AddCommand(stringr::str_c("eSet<-MulOmics(eSet=eSet,Groups='targetGroups',",
                                                     "VarsY='targetVarsY',",
                                                     "VarsC='targetVarsC',",
                                                     "TuneMethod='",TuneMethod,"',",
                                                     "TuneNum=",TuneNum,",",
                                                     "RsmpMethod='",RsmpMethod,"',",
                                                     "Folds=",Folds,",",
                                                     "VarsImpThr=",VarsImpThr,",",
                                                     "SG_Lrns='learners you choose'"))
  eSet$RCommandLog %>%
    as_tibble() %>%
    purrr::set_names("R commands") %>%
    data.table::fwrite(stringr::str_c(eSet$FileDirOut,"/rcommands log.txt"))

  eSet$ExcecutionLog %>%
    as_tibble() %>%
    purrr::set_names("running log") %>%
    data.table::fwrite(stringr::str_c(eSet$FileDirOut,"/running log.txt"))

  eSet %>%
    save(file = str_c(eSet$FileDirOut,"/eSet.Rdata"))

  tictoc::toc()

  return(eSet)
}


